from typing import Sequence
import torch
from tensordict import TensorDict, TensorDictBase
from torchrl.envs import Transform
from torchrl.envs import Compose

import gymnasium as gym
import numpy as np

from lift.environments.gym_envs import NpGymEnv, resize_gym_box_space


class TeacherEnv(gym.Wrapper):
    """Environment used to meta train teacher

    - Observations: game observation corrupted by emg policy
    - Actions: game actions generated by teacher

    Args:
        noise_range (list[float] | None): range of noise applied to corrupt teacher actions
        alpha_range (list[float] | None): range of entropy coefficient
    """
    def __init__(
        self, 
        env: NpGymEnv, 
        noise_range: list[float] | None = [0.001, 1.], 
        alpha_range: list[float] | None = [0.001, 1.],
    ):
        super().__init__(env)
        self.noise_range = noise_range
        self.alpha_range = alpha_range

        # add meta variables to observation space
        new_obs_dim = self.observation_space["observation"].shape[-1] 
        new_obs_dim += sum([noise_range != None, alpha_range != None])
        self.observation_space["observation"] = resize_gym_box_space(
            self.observation_space["observation"], new_obs_dim
        )

    def reset(self):
        obs = self.env.reset()

        # sample meta vars
        self.meta_vars = None
        meta_vars = []
        if self.noise_range is not None:
            self.noise = np.random.uniform(self.noise_range[0], self.noise_range[1])
            meta_vars.append(self.noise)
        if self.alpha_range is not None:
            self.alpha = np.random.uniform(self.alpha_range[0], self.alpha_range[1])
            meta_vars.append(self.alpha)
        
        if meta_vars != []:
            self.meta_vars = np.hstack(meta_vars, dtype=self.observation_space["observation"].dtype)
            obs["observation"] = np.concatenate([obs["observation"], self.meta_vars])
        return obs

    def step(self, action: np.ndarray):
        if self.noise_range is not None:
            eps = np.random.normal(size=action.shape) * self.noise
            decoded_action = action + eps
        else:
            decoded_action = action.copy()

        obs, rwd, done, info = self.env.step(decoded_action)

        if self.meta_vars is not None:
            obs["observation"] = np.concatenate([obs["observation"], self.meta_vars])
        return obs, rwd, done, info


class TeacherTransform(Transform):
    """Transforms observation to add meta teacher variables

    Args:
        noise_range (list[float] | None): range of noise applied to corrupt teacher actions
        alpha_range (list[float] | None): range of entropy coefficient
    """
    def __init__(
        self,
        noise_range: list[float] | None,
        alpha_range: list[float] | None,
        in_keys: Sequence[str] | None = None,
        out_keys: Sequence[str] | None = None,
        in_keys_inv: Sequence[str] | None = None,
        out_keys_inv: Sequence[str] | None = None,
    ):
        super().__init__(in_keys, out_keys, in_keys_inv, out_keys_inv)
        self.noise_range = noise_range
        self.alpha_range = alpha_range

    def _apply_transform(self, obs: torch.Tensor) -> torch.Tensor:
        if self.meta_vars is not None:
            new_obs = torch.cat([obs, self.meta_vars], dim=-1)
        else:
            new_obs = obs.clone()
        return new_obs
    
    def _inv_apply_transform(self, action: torch.Tensor) -> torch.Tensor:
        if self.noise_range is not None:
            eps = torch.randn_like(action) * self.noise
            decoded_action = action + eps
        else:
            decoded_action = action.clone()
        return decoded_action
    
    def _step(self, tensordict: TensorDictBase, next_tensordict: TensorDictBase) -> TensorDictBase:
        next_tensordict["observation"] = self._apply_transform(next_tensordict["observation"])
        return next_tensordict
    
    def _reset(self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase) -> TensorDictBase:
        self.meta_vars = None
        meta_vars = []
        if self.noise_range is not None:
            self.noise = torch.rand(1).uniform_(self.noise_range[0], self.noise_range[1])
            meta_vars.append(self.noise)
        if self.alpha_range is not None:
            self.alpha = torch.rand(1).uniform_(self.alpha_range[0], self.alpha_range[1])
            meta_vars.append(self.alpha)
        
        if meta_vars != []:
            self.meta_vars = torch.cat(meta_vars, dim=-1)
            tensordict_reset["observation"] = torch.cat([tensordict_reset["observation"], self.meta_vars], dim=-1)
        return tensordict_reset
    
    def transform_observation_spec(self, observation_spec):
        new_obs_dim = list(observation_spec["observation"].shape)
        new_obs_dim[-1] += sum([self.noise_range != None, self.alpha_range != None])
        observation_spec["observation"].shape = torch.Size(new_obs_dim)
        return observation_spec


if __name__ == "__main__":
    from torchrl.envs import TransformedEnv
    from lift.rl.utils import gym_env_maker
    np.random.seed(0)
    torch.manual_seed(0)

    # test np env
    env = NpGymEnv("FetchReachDense-v2")
    noise_range = [0.001, 1.]
    alpha_range = None
    add_dim = sum([noise_range != None, alpha_range != None])
    obs_dim = env.observation_space["observation"].shape[-1] + add_dim
    env = TeacherEnv(env, noise_range=noise_range, alpha_range=alpha_range)
    
    obs = env.reset()
    act = env.action_space.sample()
    next_obs, rwd, done, info = env.step(act)
    assert env.observation_space["observation"].shape == (obs_dim,)
    assert obs["observation"].shape == (obs_dim,)
    assert next_obs["observation"].shape == (obs_dim,)
    if add_dim > 0:
        assert np.all(obs["observation"][-add_dim:] == next_obs["observation"][-add_dim:])

    # test torchrl transform
    env = gym_env_maker("FetchReachDense-v2")
    env = TransformedEnv(env, Compose(TeacherTransform(
        noise_range, 
        alpha_range, 
        in_keys=["observation"], 
        out_keys=["observation"], 
        in_keys_inv=["action"], 
        out_keys_inv=["action"],
    )))
    
    action = TensorDict({"action": torch.randn(3)})
    obs1 = env.reset().clone()
    next_obs1 = env.step(action).clone()
    obs2 = env.reset().clone()
    next_obs2 = env.step(action).clone()
    assert obs1["observation"].shape == (obs_dim,)
    assert next_obs1["next"]["observation"].shape == (obs_dim,)
    assert obs2["observation"].shape == (obs_dim,)
    assert next_obs2["next"]["observation"].shape == (obs_dim,)
    if add_dim > 0:
        assert torch.all(obs1["observation"][..., -add_dim:] == next_obs1["next"]["observation"][..., -add_dim:]), "meta variables should be the same across steps"
        assert torch.all(obs2["observation"][..., -add_dim:] == next_obs2["next"]["observation"][..., -add_dim:]), "meta variables should be the same across steps"
        assert torch.all(obs1["observation"][..., -add_dim:] != obs2["observation"][..., -add_dim:]), "meta variables should be different across episodes"