program: scripts/train_align_teacher.py
method: bayes
metric:
  name: encoder_reward
  goal: maximize
parameters:
  mi:
    parameters:
      batch_size:
        values: [128, 256, 512]
      epochs: 
        values: [50, 70, 90, 110]
      lr:
        distribution: log_uniform_values
        min: 0.00001
        max: 0.001
      n_steps_rollout: 
        values: [ 5_000, 10_000, 20_000]
      random_pertube_prob: 
        values: [0.1, 0.3, 0.5, 0.7]
      action_noise: 
        values: [0.1, 0.3, 0.5, 0.7]
  encoder:
    parameters:
      h_dim: 
        values: [ 64, 128, 256, 512]
      tau: 
        values: [0.3, 0.5, 0.7]
      beta_1: 
        value: 1. # mi weight, use 0.5 for mse
      beta_2: 
        value: 1. # kl weight
      kl_approx_method:
        values: ["logp", "abs", "mse"]