program: scripts/pretrain_mi.py
method: bayes
metric:
  name: encoder_mae # should this be encoder_mae or val/act_mae?
  goal: minimize
parameters:
  pretrain:
    parameters:
      lr:
        distribution: log_uniform_values
        min: 0.00001
        max: 0.001
      batch_size:
        values: [ 256, 512, 750, 1000 ]
      epochs:
        values: [ 50, 70, 90, 110 ]
      num_augmentation:
        values: [ 1000, 3000, 5000, 7000 ]
  mi:
    parameters:
      beta_1:
        value: 1.0
      beta_2:
        values: [ 0.001, 0.01, 0.1 ]
      beta_3:
        values: [ 0.5, 1.0, 1.5, 2.0 ]
  encoder:
    parameters:
      hidden_size:
        values: [ 32, 64, 126, 256, 512 ]
      n_layers:
        min: 3
        max: 10
      dropout:
        min: 0.1
        max: 0.6