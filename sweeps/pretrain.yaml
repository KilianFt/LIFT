program: scripts/pretrain.py
method: bayes
metric:
  name: encoder_reward
  goal: maximize
parameters:
  pretrain:
    parameters:
      lr:
        distribution: log_uniform_values
        min: 0.00001
        max: 0.001
      batch_size:
        values: [ 128, 256, 512 ]
      epochs:
        values: [ 50, 70, 90, 110 ]
      num_augmentation:
        values: [ 10000, 20000, 30000, 40000 ]
      window_increment:
        values: [ 50, 100, 150 ]
      augmentation_distribution:
        values: ["uniform", "normal"]
  encoder:
    parameters:
      hidden_size:
        values: [ 126, 256, 512, 1024 ]
      n_layers:
        min: 1
        max: 10
      dropout:
        min: 0.1
        max: 0.5